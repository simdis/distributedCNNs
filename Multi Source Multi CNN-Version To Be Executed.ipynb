{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Source - Multi (Early-Exit) CNN Model --> Version to be Executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Definition\n",
    "\n",
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import graph as gg\n",
    "import samples\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "C = 3  # Number of CNNs\n",
    "N = 50  # Number of nodes\n",
    "xm = 15  # Space width as (-xm, +xm)\n",
    "dt = 7.5  # Transmission maximum distance\n",
    "xs = None  # Source x position (None to randomly initialize)\n",
    "ys = None  # Source y position (None to randomly initialize)\n",
    "xf = None  # Sink x position (None to randomly initialize)\n",
    "yf = None  # Sink y position (None to randomly initialize)\n",
    "sink_is_source = True  # True if Source and Sink are on the same node\n",
    "\n",
    "orange_p = 0.45  # Percentage of OrangePi Zero\n",
    "beagle_p = 0.45  # Percentage of BeagleBone AI\n",
    "pi3_p = 1 - orange_p - beagle_p  # Percentage of Raspberry Pi 3B+\n",
    "\n",
    "# Max number of layers per node\n",
    "L = 1\n",
    "# Datarate (measured in KB/s --> default is 72.2 Mb/s == 9241.6 KB/s)\n",
    "datarate = 9241.6\n",
    "# Image Size (measured in KB --> default is a floating-point RGB image of size 227x227)\n",
    "Ks = 227 * 227 * 3 * 4 / 1024\n",
    "\n",
    "# Output dir\n",
    "output_dir = 'results'\n",
    "\n",
    "# Optimization Time Limit\n",
    "time_limit = 300.0\n",
    "\n",
    "exp_id = 0\n",
    "# CNN name\n",
    "cnn_name = 'alex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = False\n",
    "while not ok:\n",
    "    # Create a graph object\n",
    "    graph = gg.create_graph(nodes=N)\n",
    "    # Create the nodes uniformly in the space\n",
    "    xpos, ypos = gg.generate_random_positions(\n",
    "        nodes=N,\n",
    "        minx=-xm, maxx=xm,\n",
    "        miny=-xm, maxy=xm\n",
    "    )\n",
    "\n",
    "    # Create the sources\n",
    "    if xs is None:\n",
    "        xs = np.random.rand(C) * 2 * xm - xm\n",
    "        ys = np.random.rand(C) * 2 * xm - xm\n",
    "        if sink_is_source:\n",
    "            xf = xs\n",
    "            yf = ys\n",
    "        else:\n",
    "            xf = np.random.rand(C) * 2 * xm - xm\n",
    "            yf = np.random.rand(C) * 2 * xm - xm\n",
    "\n",
    "    # Add the source to the graph\n",
    "    xcoords = xpos.copy()\n",
    "    ycoords = ypos.copy()\n",
    "    for i in range(C):\n",
    "        graph = gg.add_node_to_graph(graph)\n",
    "        xcoords = np.append(xcoords, xs[i])\n",
    "        ycoords = np.append(ycoords, ys[i])\n",
    "    if not sink_is_source:\n",
    "        for i in range(C):\n",
    "            graph = gg.add_node_to_graph(graph)\n",
    "            xcoords = np.append(xcoords, xf[i])\n",
    "            ycoords = np.append(ycoords, yf[i])\n",
    "\n",
    "    # Create the graph links among reachable nodes.\n",
    "    graph = gg.add_arcs_with_max_distance(\n",
    "        graph, xcoords, ycoords, dmax=dt\n",
    "    )\n",
    "\n",
    "    # Compute distances\n",
    "    distances = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            dij = gg.find_min_distance(graph, i, j)\n",
    "            distances[i, j] = dij\n",
    "            distances[j, i] = dij\n",
    "            \n",
    "    # Create the distance from the source and to the sink\n",
    "    source_dist = np.zeros((C, N))\n",
    "    dest_dist = np.zeros((C, N))\n",
    "    for c in range(C):\n",
    "        for i in range(N):\n",
    "            source_dist[c, i] = gg.find_min_distance(graph, i, N+c)\n",
    "    if sink_is_source:\n",
    "        dest_dist = source_dist\n",
    "    else:\n",
    "        for c in range(C):\n",
    "            for i in range(N):\n",
    "                dest_dist[c, i] = gg.find_min_distance(graph, i, N+C+c)\n",
    "    \n",
    "    if np.max(distances) < np.inf and np.max(source_dist) < np.inf and np.max(dest_dist) < np.inf:\n",
    "        ok = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration\n",
    "cfg_m, cfg_c, cfg_e = samples.get_node_configuration('orange_beagle_pi3')\n",
    "# Assign node configuration to each node\n",
    "sequence = np.random.choice(\n",
    "    np.arange(len(cfg_m)),\n",
    "    size=N,\n",
    "    replace=True,\n",
    "    p=np.array([orange_p, beagle_p, pi3_p])\n",
    ")\n",
    "\n",
    "# Create the data structure for Gurobi\n",
    "nodes, cbar, mbar, e = gp.multidict({\n",
    "    i: [cfg_c[s], cfg_m[s], cfg_e[s]]\n",
    "    for i, s in enumerate(sequence)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save idx for metrics\n",
    "orange_idx = np.argwhere(sequence==0).flatten()\n",
    "beagle_idx = np.argwhere(sequence==1).flatten()\n",
    "pi_idx = np.argwhere(sequence==2).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the just created network of sensors is visualized. In particular, the source and sink are represented by an orange star, the OrangePiZero nodes by the blue dots, the BeagleBone AI ones by the green diamonds, and the Raspberry Pi 3B+ by the purple crosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "gg.plot(\n",
    "    graph=graph, xpos=xcoords, ypos=ycoords, xm=xm, figsize=(15, 15),\n",
    "    color=['blue', 'green', 'purple'], marker=['o', 'D', 'X'], size=[40, 80, 60],\n",
    "    sequence=sequence, num_sources=C\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connfiguration\n",
    "cnn_k, cnn_m, cnn_e, cnn_p, cnn_g = samples.get_cnn_configuration_c(cnn_name)\n",
    "# Create the data structure for Gurobi\n",
    "layers, K, m, c, p, g = gp.multidict({\n",
    "    i: [*cnn_params_i]\n",
    "    for i, cnn_params_i in enumerate(zip(cnn_k, cnn_m, cnn_e, cnn_p, cnn_g))\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_stats(alpha, list_idxs):\n",
    "    \"\"\"\n",
    "    Function to counte the number of IoT units, per each type, used by each CNN.\n",
    "    Please note that if a node is shared among two or more CNNs is counted two or more times.\n",
    "    \"\"\"\n",
    "    stats = np.zeros((alpha.shape[0], len(list_idxs)))\n",
    "    for u in range(alpha.shape[0]):\n",
    "        au = alpha[u]\n",
    "        for i, li in enumerate(list_idxs):\n",
    "            stats[u, i] += np.sum(np.max(au[li], axis=1))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_stats(alpha):\n",
    "    stats = np.zeros(alpha.shape[0])\n",
    "    for u in range(alpha.shape[0]):\n",
    "        stats[u] = sum(\n",
    "            [alpha[u, i, j] * p[j] * c[j] / e[i]\n",
    "             for i in nodes for j in layers]\n",
    "        )\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transmission_stats(alpha):\n",
    "    stats = np.zeros(alpha.shape[0])\n",
    "    for u in range(alpha.shape[0]):\n",
    "        stats[u] = sum(\n",
    "            [alpha[u, i, j] * alpha[u, k, j+1] * p[j+1] * distances[i, k] * K[j] / datarate \n",
    "             for i in nodes for k in nodes for j in layers[:-1]]\n",
    "        ) + sum(\n",
    "            [alpha[u, i, 1] * p[1] * Ks * source_dist[u, i] / datarate\n",
    "             for i in nodes]\n",
    "        ) + sum( \n",
    "            [alpha[u, i, j] * g[j] * K[len(layers)-1] * dest_dist[u, i] / datarate\n",
    "             for i in nodes for j in layers]\n",
    "        )\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Once all the parameters have been defined, it is time to define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.Model('multi_ex_cnn_multi_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save IoT stats\n",
    "list_idx = [orange_idx, beagle_idx, pi_idx]\n",
    "for i in range(len(list_idx)):\n",
    "    np.savetxt(\n",
    "        os.path.join(output_dir, 'node_{}_idxs_exp{}.csv'.format(i, exp_id)),\n",
    "        list_idx[i], fmt='%.00f'\n",
    "    )\n",
    "# Test L from 1 to num_layers\n",
    "M = len(cnn_m)\n",
    "for L in range(M):\n",
    "    alpha = model.addVars(C, len(nodes), len(layers), vtype=GRB.BINARY, name='alpha')\n",
    "    \n",
    "    # All the layers assigned.\n",
    "    assigned_layer_constraints = \\\n",
    "        model.addConstrs((gp.quicksum(alpha[u, i, j] for i in nodes) == 1 \n",
    "                          for j in layers for u in range(C)), name='assigned_layer')\n",
    "\n",
    "    # Maximum number of layers per node\n",
    "    layers_per_node_constraints = \\\n",
    "        model.addConstrs((gp.quicksum(alpha[u, i, j] for j in layers for u in range(C)) <= (L + 1)\n",
    "                          for i in nodes), name='layers_per_node')\n",
    "\n",
    "    # Computational Constraints\n",
    "    # Note that c[u,j] is simplified in c[j] since all the CNNs are equal.\n",
    "    computational_constraints = \\\n",
    "        model.addConstrs((gp.quicksum(alpha[u, i, j] * c[j] for j in layers for u in range(C)) <= cbar[i]\n",
    "                          for i in nodes), name='computational_constraints')\n",
    "\n",
    "    # Memory Constraints\n",
    "    memory_constraints = \\\n",
    "        model.addConstrs((gp.quicksum(alpha[u, i, j] * m[j] for j in layers for u in range(C)) <= mbar[i]\n",
    "                          for i in nodes), name='memory_constraints')\n",
    "    \n",
    "    # Transmission Time + Source Time + Sink Time + Processing Time\n",
    "    # Note that K, p and g has no index u since all the CNNs are equal.\n",
    "    model.setObjective(\n",
    "        gp.quicksum(alpha[u, i, j] * alpha[u, k, j+1] * p[j+1] * distances[i, k] * K[j] / datarate \n",
    "                    for u in range(C) for i in nodes for k in nodes for j in layers[:-1]) +\n",
    "        gp.quicksum(alpha[u, i, 1] * p[1] * Ks * source_dist[u, i] / datarate\n",
    "                    for u in range(C) for i in nodes) + \n",
    "        gp.quicksum(alpha[u, i, j] * g[j] * K[len(layers)-1] * dest_dist[u, i] / datarate\n",
    "                    for u in range(C) for i in nodes for j in layers) + \n",
    "        gp.quicksum(alpha[u, i, j] * p[j] * c[j] / e[i]\n",
    "                    for u in range(C) for i in nodes for j in layers),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "    \n",
    "    # Max time_limit seconds of optimization\n",
    "    model.setParam(GRB.Param.TimeLimit, time_limit)\n",
    "    # Optimize\n",
    "    model.optimize()\n",
    "    \n",
    "    # Convert the variables to numpy\n",
    "    alpha_numpy = np.array([alpha[u, i, j].x for u in range(C) for i in nodes for j in layers]).reshape(C, len(nodes), len(layers))\n",
    "\n",
    "    # Get objective value\n",
    "    latency = model.getObjective().getValue()\n",
    "    print('The total latency is {:.3f} seconds'.format(latency))\n",
    "    \n",
    "    # Compute and save stats\n",
    "    nodes_stats = get_nodes_stats(\n",
    "        alpha=alpha_numpy, list_idxs=[orange_idx, beagle_idx, pi_idx]\n",
    "    )\n",
    "    np.savetxt(\n",
    "        os.path.join(output_dir, 'nodes_stats_exp{}_L{}.csv'.format(exp_id, L)),\n",
    "        nodes_stats, fmt='%.00f'\n",
    "    )\n",
    "    processing_stats = get_processing_stats(\n",
    "        alpha=alpha_numpy\n",
    "    )\n",
    "    np.savetxt(\n",
    "        os.path.join(output_dir, 'processing_stats_exp{}_L{}.csv'.format(exp_id, L)),\n",
    "        processing_stats, fmt='%.05f'\n",
    "    )\n",
    "    transmission_stats = get_transmission_stats(\n",
    "        alpha=alpha_numpy\n",
    "    )\n",
    "    np.savetxt(\n",
    "        os.path.join(output_dir, 'transmission_stats_exp{}_L{}.csv'.format(exp_id, L)),\n",
    "        transmission_stats, fmt='%.05f'\n",
    "    )\n",
    "    for i in range(alpha_numpy.shape[0]):\n",
    "        np.savetxt(\n",
    "            os.path.join(output_dir, 'alpha_{}_exp{}_L{}.csv'.format(i, exp_id, L)),\n",
    "            alpha_numpy[i], fmt='%.00f'\n",
    "        )\n",
    "    \n",
    "    # PLOT\n",
    "    # Plot the path per each CNN\n",
    "    path_colors = ['darkred', 'orange', 'gray', 'black', 'olive', 'magenta']\n",
    "    for u in range(C):\n",
    "        # Find path\n",
    "        path = np.argwhere(alpha_numpy[u].T==1)[:,1]\n",
    "        if u==0:\n",
    "            # First plot,\n",
    "            ax = gg.path_plot(\n",
    "                path=path, xpos=xcoords, ypos=ycoords, xm=xm, figsize=(15, 15), annotate=False,\n",
    "                color=['blue', 'green', 'purple'], marker=['o', 'D', 'X'], size=[40, 80, 60],\n",
    "                sequence=sequence, num_sources=C, path_source_idx=u,\n",
    "                out_prob=g.values(), path_color=path_colors[u]\n",
    "            )\n",
    "        else:\n",
    "            # Remaining plot, only paths\n",
    "            gg.path_plot(\n",
    "                path=path, xpos=xcoords, ypos=ycoords, xm=xm, figsize=(15, 15), annotate=False,\n",
    "                color=['blue', 'green', 'purple'], marker=['o', 'D', 'X'], size=[40, 80, 60],\n",
    "                sequence=sequence, num_sources=C, path_source_idx=u,\n",
    "                out_prob=g.values(), path_color=path_colors[u], ax=ax, plot_background=False\n",
    "            )\n",
    "    # Small plt pause to avoid the plots are kept in memory and printed all together at the end.\n",
    "    plt.pause(0.05)\n",
    "\n",
    "    model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
